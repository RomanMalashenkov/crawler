# Crawler (тестовое задание)

## Описание

Crawler обходит веб-страницы, извлекая текст из параграфов и проверяя наличие целевой ссылки. Для управления обходом он использует стек.

## Как это работает

- **Инициализация**: Приложение запрашивает у пользователя начальный и целевой URL и создает начальный и целевой узлы
- **Создание краулера**: Инициализируется краулер с заданной максимальной глубиной обхода (представлена в виде костанты)
- **Ограничение глубины**: Переходит по ссылкам на страницах до заданной глубины
- **Поиск**: Краулер обрабатывает узлы из стека, пока стек не станет пустым или не будет найдена целевая ссылка
- **Обход**: При посещении страницы извлекаются параграфы в формате HTML, параграфы делятся на предложения (также в формате HTML), в предложениях ищутся ссылки, при нахождении ссылки преобразуем HTML в предложение в понятный текст и сохраняем данные
- **Проверка целевого узла**: Если ссылка совпадает с целевым URL, краулер завершает работу и выводит путь до целевой страницы
- **Декодирование URL**: Корректно обрабатывает и декодирует URL-адреса
- **Логирование**: Все посещенные URL записываются в лог-файл

## Установка и запуск

1. Для запуска нужно установить необходимые библиотеки:
   ```sh
   go get github.com/gocolly/colly
   go get github.com/PuerkitoBio/goquery
   ```
2. Склонируйте репозиторий:
```sh
git clone <URL вашего репозитория>
cd cmd/crawler
```
3. Запустите приложение:
```sh
go run main.go
```
4. Введите начальный и целевой URL по запросу приложения.

## Технологии

- [Go](https://golang.org/) — основной язык программирования
- [Colly](http://go-colly.org/) — веб-скрапер и краулер
- [Goquery](https://github.com/PuerkitoBio/goquery) — парсер HTML



# Условие ТЗ

Входные данные:
1) 2 ссылки на wikipedia (можно из файла, можно из консоли вводить);
2) ссылки за пределами wikipedia путем не считаются;
3) вручную от одной страницы до второй можно дойти за 3 клика (см. пример);
4) необходимо показать полный путь, как пройти от ссылки 1 до ссылки 2;
5) отображение пути для каждого шага должно содержать текст (полное предложение в котором эта ссылка найдена) и ссылку на следующую страницу;
6) отображать это можно как в консоли, так и в web;
7) дополнительно можно вести лог файл со всеми страницами, что были посещены при поиске.

Пример работы:
Данный пример дается кандидату.
Исходные ссылки: 
    стартовая - [https://ru.wikipedia.org/wiki/Xbox_360_S](https://ru.wikipedia.org/wiki/Xbox_360_S)
    конечная - [https://ru.wikipedia.org/wiki/Nintendo_3DS](https://ru.wikipedia.org/wiki/Nintendo_3DS)
Ожидаемый вывод:
```sh
1------------------------
И 15 июня 2010 года Microsoft подтвердили их на выставке E³, объявив о прекращении производства старых версий Xbox 360 и скором старте продаж усовершенствованной версии консоли.
https://ru.wikipedia.org/wiki/Electronic_Entertainment_Expo
2-------------------------
Это совпало с появлением нового поколения консолей, в частности с выпуском Sega Saturn, и анонсами предстоящих релизов PlayStation, Virtual Boy и Neo Geo CD.
https://ru.wikipedia.org/wiki/Virtual_Boy
3-------------------------
Стереоскопическая технология в игровых приставках вновь появилась в более поздние годы и имела больший успех, включая портативную игровую приставку Nintendo 3DS
https://ru.wikipedia.org/wiki/Nintendo_3DS
```